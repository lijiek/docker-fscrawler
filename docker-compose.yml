# Even though latest ATM is 3,
# sticking wtih 2.1 for the "condition" in "depends_on"
# It was deprecated in version 3
# Check https://docs.docker.com/compose/startup-order/
version: '2.1'

services:

  # fscrawler service for indexing a folder
  # Also check `fscrawlerrest` service for REST access
  fscrawler:
    build:
      # ubuntu as base image
      context: ${PWD}
      # alpine linux as base image
      # context: ${PWD}/alpine
    volumes:
    - ${PWD}/test/data/:/usr/share/fscrawler/data/:ro
    - ${PWD}/config/docker-compose:/usr/share/fscrawler/config-mount/docker-compose

    # Despite the python tester having a built-in healthcheck at tests/es_acceptance.py#wait_for_cluster_health
    # Using the dockerfile healthcheck extends this to other services without having to re-code a wait for health status in each
    # Note that this requires docker-compose.yml version 2.1, docker-compose>=1.11, docker>=1.13 
    depends_on:
      # Should be es_init here, but not sure why fscrawler fails to detect it has executed
      # This "depends_on.condition" syntax is deprecated anyway, so not thinking it through
      # es_init:
      elasticsearch1:
        condition: service_healthy
    networks:
      - fscrawler-networks

    command:
      - --trace
      - --config_dir
      - /usr/share/fscrawler/config
      - docker-compose

  elasticsearch1:
    environment:
      - xpack.security.enabled=false
      - xpack.monitoring.enabled=false
      - xpack.ml.enabled=false
      - xpack.graph.enabled=false
      - xpack.watcher.enabled=false
    ports: # Expose ElasticSearch ports
      - "9300:9300"
      - "9200:9200"

    build:
      # build a dockerfile on top of the official elasticsearch docker image hosted at docker.elastic.co
      # It includes healthcheck
      # Check build/elasticsearch/Dockerfile for more details
      context: ${PWD}/build/elasticsearch
    networks:
      - fscrawler-networks


  kibana1:
    build:
      context: ${PWD}/build/kibana
    environment:
     - ES_URL=http://elasticsearch1:9200
     #- "ELASTICSEARCH_URL=http://elasticsearch:9200"
    ports: # Expose ElasticSearch ports
      - "5601:5601"
    links:
      - elasticsearch1
    depends_on:
      elasticsearch1:
        condition: service_healthy
    networks:
      - fscrawler-networks



  # service that serves .travis.yml to make curl calls to elasticsearch1 and fscrawler
  tester:
    build:
      context: ${PWD}/build/tester/
    volumes:
    - ${PWD}/test/data/:/usr/share/fscrawler/data/:ro
    networks:
      - fscrawler-networks


  # worker service that uploads example pipeline
  es_init:
    build:
      context: ${PWD}/build/es_init/
    depends_on:
      elasticsearch1:
        condition: service_healthy
    environment:
      - ES_URL=http://elasticsearch1:9200
    networks:
      - fscrawler-networks


  # cannot name service with underscores
  # https://github.com/dadoonet/fscrawler/issues/474
  fscrawlerrest:
    build:
      context: ${PWD}
      # alpine
      # context: ${PWD}/alpine

    volumes:
    - ${PWD}/test/data/:/usr/share/fscrawler/data/:ro
    - ${PWD}/config/fscrawler_rest:/usr/share/fscrawler/config-mount/fscrawler_rest
    # check note above in fscrawler.depends_on
    depends_on:
      elasticsearch1:
        condition: service_healthy
    ports:
      - "8890:8080"
    networks:
      - fscrawler-networks

    command:
      - --trace
      - --config_dir
      - /usr/share/fscrawler/config
      - --loop
      - "0"
      - --rest
      - fscrawler_rest

networks:
  fscrawler-networks:
    driver: bridge

